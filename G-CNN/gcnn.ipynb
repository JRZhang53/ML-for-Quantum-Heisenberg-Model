{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import escnn.gspaces as gspaces\n",
    "import escnn.nn as enn\n",
    "import escnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import seaborn as sns\n",
    "from sympy.combinatorics import Permutation, PermutationGroup\n",
    "\n",
    "import netket as nk\n",
    "import os\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "import json\n",
    "\n",
    "PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "tensor([[-0.5981,  0.0977,  0.2979, -1.0878]])\n",
      "Allocated: 0 B\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "torch.set_default_device(device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0),1), 'B')\n",
    "    print('Reserved: ', round(torch.cuda.memory_reserved(0),1), 'B')\n",
    "    print()\n",
    "    torch.set_default_device('cuda')\n",
    "\n",
    "# test\n",
    "T = torch.randn(1, 4).to(device)\n",
    "print(T)\n",
    "print('Allocated:', round(torch.cuda.memory_allocated(0),1), 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Table of All Possible States Indexed in Lexigraphical Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateStateTable(n,n0,N): # assumes ab > n0 > 0 and N = n choose n0\n",
    "    states = []\n",
    "    state = np.concatenate((np.ones(n-n0),-1*np.ones(n0))).astype(int)\n",
    "    for i in range(0,N):\n",
    "        states.append(np.copy(state))\n",
    "        j = 0\n",
    "        flag = True\n",
    "        flip_count = 0\n",
    "        up_count = 0\n",
    "        while (flag): \n",
    "            if (j == n-1):\n",
    "                for m in range(0,n):\n",
    "                    if (state[m] != 1 and state[m+1] == 1):\n",
    "                        flip_count += 1\n",
    "                if (flip_count == 1):\n",
    "                    break\n",
    "            if (state[j] != 1):\n",
    "                j += 1  \n",
    "            elif (state[j+1] != 1):\n",
    "                for m in range(0,j):\n",
    "                    if (state[m] != 1 and state[m+1] == 1):\n",
    "                        flip_count += 1\n",
    "                    if (state[m] == 1):\n",
    "                        up_count += 1\n",
    "                if (flip_count == 1):\n",
    "                    state[j],state[j+1] = state[j+1],state[j]\n",
    "                    for k in range(1,up_count+1):\n",
    "                        state[j-k],state[k-1] = state[k-1],state[j-k]\n",
    "                else:\n",
    "                    state[j],state[j+1] = state[j+1],state[j]\n",
    "                flag = False\n",
    "            else:\n",
    "                j += 1\n",
    "    return torch.tensor(states, dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Adjacency Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, position, xadj, yadj):\n",
    "        self.position = position\n",
    "        self.xadj = xadj\n",
    "        self.yadj = yadj\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.position} {self.xadj} {self.yadj}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squareAdjacencyList(a,b): # constructs a periodic adjacency graph with width a and height b\n",
    "    nodes = []\n",
    "    for j in range(0,b):\n",
    "        for i in range(0,a):\n",
    "            xadj = [[(i-1) % a,j],[(i+1) % a,j]]\n",
    "            yadj = [[i,(j-1) % b],[i,(j+1) % b]]\n",
    "            nodes.append(Node([[i,j]],xadj,yadj))\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Neighbors Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstneighbors(a,b): \n",
    "    nodes = squareAdjacencyList(a,b)\n",
    "    N = a*b\n",
    "    J = [[0 for col in range(N)] for row in range(N)]\n",
    "\n",
    "    for i in range(0,N-1):\n",
    "        for j in range(i+1,N):\n",
    "            flag = False\n",
    "            for xptr in nodes[i].xadj:\n",
    "                if xptr in nodes[j].position:\n",
    "                    flag = True\n",
    "            for yptr in nodes[i].yadj:\n",
    "                if yptr in nodes[j].position:\n",
    "                    flag = True\n",
    "            if flag:\n",
    "                J[i][j] = 1\n",
    "                J[j][i] = 1\n",
    "        \n",
    "    return torch.tensor(J, dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Neighbors (Euclidean) Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secondneighbors(a,b):\n",
    "    nodes = squareAdjacencyList(a,b)\n",
    "    N = a*b\n",
    "    J = [[0 for col in range(N)] for row in range(N)]\n",
    "\n",
    "    for i in range(0,N-1):\n",
    "        for j in range(i+1,N):\n",
    "            flag = False\n",
    "\n",
    "            for xptr in nodes[i].xadj:\n",
    "                try:\n",
    "                    for k in range(0,N):\n",
    "                        if xptr in nodes[k].position:\n",
    "                            intermediate = k\n",
    "                    for yptr in nodes[intermediate].yadj:\n",
    "                        if yptr in nodes[j].position:\n",
    "                            flag = True\n",
    "                except UnboundLocalError:\n",
    "                    pass\n",
    "\n",
    "            if flag:\n",
    "                J[i][j] = 1\n",
    "                J[j][i] = 1\n",
    "\n",
    "    return torch.tensor(J, dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 4 # x-range of supercell\n",
    "b = 4 # y-range of supercell\n",
    "N1 = firstneighbors(a,b)\n",
    "N2 = secondneighbors(a,b)\n",
    "n = a*b # number of sites in lattice\n",
    "\n",
    "n0 = n // 2 # number of down spins in the string (taken as floor(n/2))\n",
    "N = int(math.factorial(n)/(math.factorial(n0)*math.factorial(n-n0))) # number of states\n",
    "\n",
    "stateTable = generateStateTable(n,n0,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stateValBin(state):\n",
    "    sum = 0\n",
    "    for i in range(len(state)):\n",
    "        if state[i] == 1:\n",
    "            sum += 2**i\n",
    "    return sum\n",
    "\n",
    "def searchState(state):\n",
    "    high = N-1\n",
    "    low = 0\n",
    "    while True:\n",
    "        mid = math.floor((high+low)/2)\n",
    "        if np.array_equal(state,stateTable[mid]):\n",
    "            return mid\n",
    "        elif stateValBin(state) > stateValBin(stateTable[mid]):\n",
    "            low = mid+1\n",
    "        else:\n",
    "            high = mid-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define G-CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the group and input/output types\n",
    "gspace = gspaces.rot2dOnR2(N=4)  # Example for rotation group of order 4 (D4)\n",
    "input_type = enn.FieldType(gspace, [gspace.trivial_repr])  # Scalar fields\n",
    "output_type = enn.FieldType(gspace, [gspace.trivial_repr])  # Single scalar output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeriodicConvLayer(enn.EquivariantModule):\n",
    "    def __init__(self, in_type, out_type, kernel_size):\n",
    "        super(PeriodicConvLayer, self).__init__()\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = enn.R2Conv(in_type, out_type, kernel_size, padding=0)\n",
    "        \n",
    "    def periodic_padding(self, x, padding):\n",
    "        return torch.nn.functional.pad(x, padding, mode='circular')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        padding = self.kernel_size // 2\n",
    "        x = self.periodic_padding(x.tensor, (padding, padding, padding, padding))\n",
    "        x = enn.GeometricTensor(x, self.conv.in_type)\n",
    "        return self.conv(x)\n",
    "    \n",
    "    def evaluate_output_shape(self, input_shape):\n",
    "        padding = self.kernel_size // 2\n",
    "        return self.conv.evaluate_output_shape(input_shape[:-2] + (input_shape[-2] + 2 * padding, input_shape[-1] + 2 * padding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the network\n",
    "class GCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCNN, self).__init__()\n",
    "        \n",
    "        self.block1 = PeriodicConvLayer(input_type, enn.FieldType(gspace, 8*[gspace.regular_repr]), kernel_size=4)\n",
    "        self.block2 = PeriodicConvLayer(enn.FieldType(gspace, 8*[gspace.regular_repr]), enn.FieldType(gspace, 16*[gspace.regular_repr]), kernel_size=4)\n",
    "        self.block3 = PeriodicConvLayer(enn.FieldType(gspace, 16*[gspace.regular_repr]), output_type, kernel_size=4)\n",
    "        self.pool = enn.PointwiseAvgPoolAntialiased(output_type, sigma=0.66, stride=1)\n",
    "        \n",
    "        self.linear = nn.Linear(49, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = enn.GeometricTensor(x, input_type)\n",
    "        x = self.block1(x)\n",
    "        x = nn.functional.relu(x.tensor)\n",
    "        x = enn.GeometricTensor(x, self.block2.conv.in_type)\n",
    "        x = self.block2(x)\n",
    "        x = nn.functional.relu(x.tensor)\n",
    "        x = enn.GeometricTensor(x, self.block3.conv.in_type)\n",
    "        x = self.block3(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x.tensor, 1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Estimation Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAdjStates(initState): ### takes some basis state and returns a list of all other states that have a nonzero Hamiltonian with it\n",
    "    otherStates = []\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        for j in range(i+1,n):\n",
    "            if (N1[i][j] != 0 or N2[i][j] !=0) and initState[i]*initState[j] == -1:\n",
    "                tempState = initState.clone()\n",
    "                tempState[i],tempState[j] = initState[j],initState[i]\n",
    "                otherStates.append(tempState)                \n",
    "\n",
    "    return otherStates\n",
    "    \n",
    "def computeExplicitHamEntry(state1,state2,J1,J2,diagonal):\n",
    "    sum = 0.0\n",
    "    if diagonal:\n",
    "        for k in range(0,n-1):\n",
    "            for l in range(k+1,n):\n",
    "                if (N1[k][l] != 0):\n",
    "                    sum += J1*state1[k]*state2[l]\n",
    "                if (N2[k][l] != 0):\n",
    "                    sum += J2*state1[k]*state2[l]          \n",
    "    else:\n",
    "        tempState = state1 * state2\n",
    "        if (torch.count_nonzero(tempState == -1) == 2):\n",
    "            indices = np.where(tempState == -1)\n",
    "            e,f = indices[0][0],indices[0][1]\n",
    "            if (N1[e][f] != 0):\n",
    "                sum += 2*J1\n",
    "            if (N2[e][f] != 0):\n",
    "                sum += 2*J2\n",
    "    \n",
    "    return sum\n",
    "\n",
    "def locEnergy(model,initState,coeff,J1,J2):\n",
    "    sum = 0.0\n",
    "    others = findAdjStates(initState)\n",
    "    for x in others:\n",
    "        c_x = model(torch.tensor(x.reshape(1,1,a,b), dtype=torch.float, requires_grad=True)).item()\n",
    "        H_x = computeExplicitHamEntry(initState,x,J1,J2,False)\n",
    "        sum += c_x*H_x\n",
    "    sum /= coeff\n",
    "    sum += computeExplicitHamEntry(initState,initState,J1,J2,True)\n",
    "    return sum\n",
    "\n",
    "def metropolis(model,initState,coeff):\n",
    "    proposedState = torch.tensor([1]*(n-n0)+[-1]*n0, dtype=torch.float, requires_grad=True)\n",
    "    proposedState[torch.randperm(proposedState.size(0))]\n",
    "    newCoeff = model(torch.tensor(proposedState.reshape(1,1,a,b), dtype=torch.float, requires_grad=True)).item()\n",
    "    acceptanceProb = min(1,(newCoeff/coeff)**2)\n",
    "    bernTrial = torch.bernoulli(torch.tensor([acceptanceProb],dtype=torch.float, requires_grad=True)).item()\n",
    "    if bernTrial == 1:\n",
    "        return proposedState\n",
    "    else:\n",
    "        return initState\n",
    "\n",
    "def sampleEnergy(model,batchSize,J1,J2): ### takes in basis state index\n",
    "    ignore = 10 # number of MCMC steps to ignore (in order to reduce correlation)\n",
    "    state = torch.tensor([1]*(n-n0)+[-1]*n0, dtype=torch.float, requires_grad=True)\n",
    "    state = state[torch.randperm(state.size(0))]\n",
    "    for i in range(ignore):\n",
    "        c = model(torch.tensor(state.reshape(1,1,a,b), dtype=torch.float, requires_grad=True)).item()\n",
    "        state = metropolis(model,state,c)\n",
    "\n",
    "    sum = 0.0\n",
    "    for step in range(batchSize):\n",
    "        c = model(torch.tensor(state.reshape(1,1,a,b), dtype=torch.float, requires_grad=True)).item()\n",
    "        sum += locEnergy(model,state,c,J1,J2)\n",
    "        state = metropolis(model,state,c)\n",
    "    \n",
    "    return sum / batchSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, J1, J2, batchSize, numEpochs, lr):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(numEpochs)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = sampleEnergy(model,batchSize,J1,J2)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]C:\\Users\\jerry\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n",
      "100%|██████████| 100/100 [30:27<00:00, 18.27s/it]  \n"
     ]
    }
   ],
   "source": [
    "J1 = 1\n",
    "J2 = 0\n",
    "batchSize = 50\n",
    "numEpochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "trainModel(model,J1,J2,batchSize,numEpochs,lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), PATH + '/4x4model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNN().to(device)\n",
    "model.load_state_dict(torch.load(PATH + '/4x4model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
